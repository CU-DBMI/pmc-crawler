{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2747125",
   "metadata": {},
   "source": [
    "# Published Items for the Center for Health AI - Monthly\n",
    "\n",
    "This takes a list of authors and searches for any items published for the provided month, grabs the proper citation from manubot-cite, and creates a markdown and MS Word document.\n",
    "\n",
    "The smartsheet with the author search terms can be found here: https://app.smartsheet.com/sheets/rCfg3F64V9c4wH6Q9vcwQwqxF8XqhWJchpQfgRR1?view=grid\n",
    "\n",
    "- 2021/12/20 First demo (ST)\n",
    "- 2022/01/18 Fetch pubmed instead of PMC ids (ST)\n",
    "- 2022/01/19 Added caching to help dev go faster (ST)\n",
    "- 2022/06/24 Changes for monthly counts (DB)\n",
    "- 2022/06/12 Pull user list from smartsheet (ST)\n",
    "- 2022/08/09 Include ORCiD in search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8dd49-601f-42d9-86f2-161d5d3b2288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# when cells finish running, triggers a push notification in compatible browsers\n",
    "!pip install jupyterlab_notify\n",
    "%load_ext jupyterlab_notify\n",
    "%notify_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33d948-2ec7-499a-b19f-ce03d177f21f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import calendar\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import copy\n",
    "import subprocess\n",
    "import time\n",
    "from dateutil import parser\n",
    "from datetime import date, datetime, timedelta\n",
    "from typing import Dict, List, Union\n",
    "import numpy as np\n",
    "import manubot\n",
    "import pandas as pd\n",
    "import requests\n",
    "import smartsheet\n",
    "import scrapbook as sb\n",
    "import dotenv\n",
    "\n",
    "from prefect import task, flow\n",
    "from prefect.client import get_client\n",
    "\n",
    "from manubot.cite.citations import Citations\n",
    "from manubot.cite.citekey import citekey_to_csl_item\n",
    "from citeproc.source.json import CiteProcJSON\n",
    "from citeproc import CitationStylesStyle, CitationStylesBibliography\n",
    "from citeproc import Citation, CitationItem\n",
    "from citeproc import formatter\n",
    "\n",
    "from ratelimit import RateLimitException, limits, sleep_and_retry\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG, stream=sys.stdout, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e253856-8f0f-43e9-aa09-5a008ac819d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set variables from the environment\n",
    "BUILD_FOLDER_PREFIX = os.environ.get(\"BUILD_FOLDER_PREFIX\", \"/app/_build\")\n",
    "\n",
    "# (Optional) NCBI API key\n",
    "NCBI_API_KEY = os.environ.get('NCBI_API_KEY')\n",
    "# (Optional) NCBI API email\n",
    "NCBI_API_EMAIL = os.environ.get('NCBI_API_EMAIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0aa77",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Papermill Parameters Cell\n",
    "# These can be used as arguments via papermill\n",
    "\n",
    "# Set any dates (as string in the format yyyy/mm/dd) for searching a month's cites\n",
    "# Leave these empty to generate for the current month.\n",
    "start_date: str = \"2024/02/01\"\n",
    "end_date: str = \"2023/03/01\"\n",
    "\n",
    "# this is the ID from jerome's \"DBMI Contact List\" spreadsheet\n",
    "# it appears to contain the correct info, so we're going with this\n",
    "authors_sheet_id:int = os.environ.get('AUTHORS_SHEET_ID', -1)\n",
    "\n",
    "# alternatively, the user may supply a path to a file\n",
    "authors_sheet_path:str = os.environ.get('AUTHORS_SHEET_PATH')\n",
    "\n",
    "# the name of the department by which to filter authors, i.e. the value on which to match against the \"Primary Department\" column\n",
    "# if null or blank, disables filtering by department\n",
    "department:str = None\n",
    "\n",
    "# the display name of the department, used to customize the report\n",
    "department_name:str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b65d7-f9e3-49f0-b3ff-1d09d4d578cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !!!!!\n",
    "\n",
    "# # FIXME: remove this when we're actually using it\n",
    "\n",
    "# # Customizations for Physiology & Biophysics\n",
    "# # authors_sheet_path = \"/app/input_sheets/DBMI Contact List.xlsx\" \n",
    "# authors_sheet_path = \"/app/input_sheets/Physiology & Biophysics Contact List.xlsx\"\n",
    "# # authors_sheet_path = \"/app/input_sheets/Dec 1st 2023 - Physiology & Biophysics Contact List.xlsx\"\n",
    "\n",
    "# start_date = \"2024/03/01\"\n",
    "# end_date = \"2024/03/31\"\n",
    "# # start_date = \"2023/01/01\"\n",
    "# # end_date = \"2024/01/31\"\n",
    "\n",
    "# department_name = \"Department of Physiology & Biophysics\"\n",
    "\n",
    "# !!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f7e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first, determine if the user is supplying a local file, in which case don't do anything with smartsheet\n",
    "author_sheet_valid = authors_sheet_path is not None and authors_sheet_path.strip() != \"\"\n",
    "\n",
    "# check the environment vars for secrets\n",
    "\n",
    "try:\n",
    "    env_file = \"/app/.env\"\n",
    "    log.info(\"Loading the .env file from %s\", env_file)\n",
    "    dotenv.load_dotenv(dotenv.find_dotenv(env_file))\n",
    "except OSError as ex:\n",
    "    print(f\".env file not found, continuing... (Exception: {ex})\")\n",
    "\n",
    "if not author_sheet_valid:\n",
    "    assert os.environ.get(\"SMARTSHEET_KEY\"), f\"SMARTSHEET_KEY not found in the environment\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ea81b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def month_end_date(a_date: str) -> (str, str):\n",
    "    \"\"\"\n",
    "    Calculate the month start and end date, given _any_ date.\n",
    "\n",
    "    Returns month_start_date, month_end_date.\n",
    "    \"\"\"\n",
    "    date_format_string = \"%Y/%m/%d\"\n",
    "\n",
    "    this_date = datetime.strptime(a_date, date_format_string)\n",
    "    month = this_date.month\n",
    "    year = this_date.year\n",
    "\n",
    "    start_date = f\"{year}/{month}/1\"\n",
    "\n",
    "    month += 1\n",
    "    if month == 13:\n",
    "        month = 1\n",
    "        year += 1\n",
    "\n",
    "    work_date = datetime.strptime(f\"{year}/{month}/1\", date_format_string)\n",
    "    end_date = (work_date - timedelta(days=1)).strftime(date_format_string)\n",
    "\n",
    "    return start_date, end_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0dc3e-d1dd-436c-8061-7a59c7efc4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "month_end_date(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2220454-3122-4fa8-81f8-28a9df3675b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepared_date = datetime.today().strftime(\"%Y/%m/%d\")\n",
    "\n",
    "if end_date:\n",
    "    # if the parameter date has been set, use it...\n",
    "    month_starting_date, month_ending_date = month_end_date(end_date)\n",
    "else:\n",
    "    # ... otherwise use today.\n",
    "    month_starting_date, month_ending_date = month_end_date(prepared_date)\n",
    "\n",
    "BUILD_MARKDOWN_FILEROOT = f\"cites_monthly-{month_ending_date.replace('/','-')}\"\n",
    "BUILD_MARKDOWN_FILENAME = f\"{BUILD_MARKDOWN_FILEROOT}.md\"\n",
    "BUILD_SHEET_FILENAME = f\"{BUILD_MARKDOWN_FILEROOT}.xlsx\"\n",
    "BUILD_PDF_FILENAME = f\"{BUILD_MARKDOWN_FILEROOT}.pdf\"\n",
    "BUILD_DOCX_FILENAME = f\"{BUILD_MARKDOWN_FILEROOT}.docx\"\n",
    "\n",
    "print(month_starting_date, month_ending_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b98f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# override the month start date from parameters if any\n",
    "if start_date:\n",
    "    month_starting_date = start_date\n",
    "    \n",
    "# override the ending date, too (why did it ever work differently?)\n",
    "if end_date:\n",
    "    month_ending_date = end_date\n",
    "\n",
    "month_starting_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc56cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set rate limit based on whether there's an API_KEY\n",
    "# based on NCBI requirements\n",
    "if NCBI_API_KEY:\n",
    "    NCBI_RATE_LIMIT = 10\n",
    "else:\n",
    "    NCBI_RATE_LIMIT = 3\n",
    "\n",
    "NCBI_RATE_LIMIT\n",
    "\n",
    "# the duration, in seconds, during which we can issue NCBI_RATE_LIMIT calls\n",
    "NCBI_CALL_PERIOD = 3 # from NCBI's docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977e046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure the output folder exists, and group the results of this run into a folder created from the start and end date\n",
    "BUILD_FOLDER = os.path.join(BUILD_FOLDER_PREFIX, f\"{month_starting_date}_to_{month_ending_date}\".replace(\"/\", \"-\"))\n",
    "\n",
    "# will write out to a folder\n",
    "if not os.path.exists(BUILD_FOLDER):\n",
    "    os.makedirs(BUILD_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbce8c",
   "metadata": {},
   "source": [
    "## Fetch authors list\n",
    "\n",
    "Uses whichever one of `authors_sheet_id` or `authors_sheet_path` is specified to fetch the list of authors. If it's the `_id` version, the sheet is fetched from Smartsheet by its ID, whereas if it's `_path` it's loaded from a local Excel/CSV file. If both are specified, an error is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d53b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if author_sheet_valid:\n",
    "    print(f\"Loading authors from local spreadsheet file: {authors_sheet_path}\")\n",
    "    \n",
    "    from pathlib import Path\n",
    "    # load up the local file instead\n",
    "    pth = Path(authors_sheet_path)\n",
    "    authors_df = pd.read_excel(pth)\n",
    "    \n",
    "elif authors_sheet_id is not None and str(authors_sheet_id).strip() != '' and int(authors_sheet_id) != -1:\n",
    "    print(f\"Loading authors from Smartsheet by ID: {authors_sheet_id}\")\n",
    "    \n",
    "    # connect smartsheet client\n",
    "    ss_client = smartsheet.Smartsheet(os.environ.get(\"SMARTSHEET_KEY\"))\n",
    "    ss_client.errors_as_exceptions(True)\n",
    "\n",
    "    # authors_sheet = ss_client.Reports.get_report(authors_sheet_id)\n",
    "    # the above fetched a report, but i have no idea what that is...\n",
    "    # we'll fetch the sheet instead using the \"alt\" ID\n",
    "    authors_sheet = ss_client.Sheets.get_sheet(authors_sheet_id)\n",
    "\n",
    "    # break down the cell IDs into a quick lookup box\n",
    "    cell_ids = [\"Row ID\"]\n",
    "    for column in authors_sheet.columns:\n",
    "        my_column = column.to_dict()\n",
    "        cell_ids.append(my_column[\"title\"] or \"NO_TITLE\")\n",
    "\n",
    "    # cell_ids\n",
    "\n",
    "    # break down the cells into a list of lists for a later dataframe\n",
    "    rows_list = []\n",
    "    for row in authors_sheet.rows:\n",
    "        row_list = [row.id]\n",
    "        for cell in row.cells:\n",
    "            if cell.display_value:\n",
    "                row_list.append(cell.display_value)\n",
    "            else:\n",
    "                # just in case there's a None in here, use NaN instead\n",
    "                if cell.value:\n",
    "                    row_list.append(cell.value)\n",
    "                else:\n",
    "                    row_list.append(np.NaN)\n",
    "\n",
    "        rows_list.append(row_list)\n",
    "    \n",
    "    # put it together as a dataframe\n",
    "    authors_df = pd.DataFrame(rows_list, columns=cell_ids)\n",
    "\n",
    "else:\n",
    "    raise Exception(\"One of authors_sheet_path or authors_sheet_id must be specified, but neither were provided.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd648053",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only want primary\n",
    "if department and department.strip() != \"\":\n",
    "    authors_df = authors_df.loc[authors_df[\"Primary Department\"] == department]\n",
    "\n",
    "authors_df.set_index(\"Official Name\", inplace=True)\n",
    "authors_df[\"NCBI search term\"].fillna(\"\", inplace=True)\n",
    "authors_df[\"ORCID number\"].fillna(\"\", inplace=True)\n",
    "# authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ac9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_term(row):\n",
    "    \"\"\"\n",
    "    Function to build up the search term. Used by a dataframe apply()\n",
    "    \n",
    "    https://pubmed.ncbi.nlm.nih.gov/help/\n",
    "    \"\"\"\n",
    "    \n",
    "    search_terms = []\n",
    "    \n",
    "    if row['ORCID number']:\n",
    "        orcid_term = f\"(orcid {row['ORCID number']} [auid])\"\n",
    "        #orcid_term = f\"({row['ORCID number']}[Author - Identifier])\"\n",
    "        search_terms.append(orcid_term)\n",
    "        \n",
    "    if row[\"NCBI search term\"]:\n",
    "        search_terms.append(row[\"NCBI search term\"])\n",
    "\n",
    "    if len(search_terms) > 0:\n",
    "        # group the search terms with an OR, then and that group with CU\n",
    "        return f'(({\" OR \".join(search_terms)}) AND (\"University of Colorado\"))'\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d22ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the logic for the search terms\n",
    "authors_df['full NCBI search term'] = authors_df.apply(build_search_term, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531499e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cache requests to NCBI so these can be accelerated on subsequent runs\n",
    "import requests_cache\n",
    "\n",
    "session = requests_cache.CachedSession('ncbi_authors_cache')\n",
    "\n",
    "# if we hit an error, start with the default wait and double it every time we hit an error again for this URL\n",
    "backoff = NCBI_CALL_PERIOD\n",
    "\n",
    "# FIMXE: because we run multiple requests in a loop within this function, these limits are only\n",
    "#  respected for each unique query. the code that runs a single request should be pulled out\n",
    "#  into its own function with these decorators applied to it.\n",
    "@sleep_and_retry\n",
    "@limits(calls=NCBI_RATE_LIMIT, period=NCBI_CALL_PERIOD)\n",
    "def search_ncbi(\n",
    "    term: str,\n",
    "    mindate: str,\n",
    "    maxdate: str,\n",
    "    api_key: str = None,\n",
    "    email: str = NCBI_API_EMAIL,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Look up IDs given a search term,\n",
    "    a beginning year, and an optional API key.\n",
    "\n",
    "    NCBI asks that we use an API key,\n",
    "    which increases API calls to 10/minute, instead of 3/minute.\n",
    "\n",
    "    Returns status code and a list of IDs\n",
    "    \"\"\"\n",
    "\n",
    "    # the delay before we reissue a request; reset to NCBI_CALL_PERIOD if we succeed\n",
    "    # doubled every time we make an error\n",
    "    global backoff\n",
    "\n",
    "    # log.info(f\"Looking up NCBI records for {term}, between {mindate} and {maxdate}.\")\n",
    "    ids = []\n",
    "\n",
    "    params = {\n",
    "        \"term\": term,\n",
    "        \"format\": \"pmid\",\n",
    "        \"tool\": \"CUAnschutz-Center_for_Health_AI-DEV\",\n",
    "        \"email\": email,\n",
    "        \"format\": \"json\",\n",
    "        \"retmax\": 100,\n",
    "        \"retstart\": 0,\n",
    "        # note: date format is in yyyy/mm/dd\n",
    "        \"mindate\": mindate,\n",
    "        \"maxdate\": maxdate,\n",
    "    }\n",
    "\n",
    "    if api_key:\n",
    "        params[\"api_key\"] = api_key\n",
    "\n",
    "    # page through the results until there are no more ids\n",
    "    while True:\n",
    "        r = session.get(\n",
    "            \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\", params=params\n",
    "        )\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            result = r.json()[\"esearchresult\"]\n",
    "            # reset the backoff if it went ok\n",
    "            backoff = NCBI_CALL_PERIOD\n",
    "        else:\n",
    "            # exponentially back off\n",
    "            backoff *= 2 # double the backoff\n",
    "\n",
    "            try:\n",
    "                data = r.json()\n",
    "            except:\n",
    "                data = None\n",
    "\n",
    "            log.error(f\"NCBI returned a status code of {r.status_code} for URL: {r.url}; retrying in {backoff} seconds... (Details: {data or 'n/a'})\")\n",
    "\n",
    "            time.sleep(backoff) # sleep for a while\n",
    "            break # and try again\n",
    "\n",
    "        if len(result[\"idlist\"]) == 0:\n",
    "            # no more IDs\n",
    "            break\n",
    "        else:\n",
    "            # append the IDs to the results...\n",
    "            ids = ids + result[\"idlist\"]\n",
    "            # and move the start chunk up by the size of retmax\n",
    "            params[\"retstart\"] += params[\"retmax\"]\n",
    "\n",
    "    return r.status_code, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc3a02",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "\n",
    "# I would like to do this in parallel, but the deal with NCBI is we agree not to do that\n",
    "id_dict = {}\n",
    "\n",
    "log.info(\n",
    "    f\"Looking up pubmed IDs from NCBI between {month_starting_date} and {month_ending_date}\"\n",
    ")\n",
    "\n",
    "skipped_authors = set()\n",
    "\n",
    "with logging_redirect_tqdm():\n",
    "    for author, row in tqdm(authors_df.iterrows(), total=authors_df.shape[0]):\n",
    "        if row['full NCBI search term']:\n",
    "            search_term = row['full NCBI search term']\n",
    "        else:\n",
    "            log.warning(f\"Cannot find a search term for `{author}`\")\n",
    "            skipped_authors.add(author)\n",
    "            continue\n",
    "\n",
    "        log.info(f\"Looking up `{author}` using {search_term}\")\n",
    "        status_code, ids = search_ncbi(\n",
    "            term=search_term,\n",
    "            mindate=month_starting_date,\n",
    "            maxdate=month_ending_date,\n",
    "            api_key=NCBI_API_KEY,\n",
    "        )\n",
    "        log.debug(\"pubmed ids fetched from NCBI: %s\", ids)\n",
    "\n",
    "        for id in ids:\n",
    "            if not id_dict.get(id):\n",
    "                # create an empty nested dict\n",
    "                id_dict[id] = {\"authors\": []}\n",
    "            id_dict[id][\"authors\"].append(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d47c0-badd-4081-b857-9c141eafc829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd20020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a list of pubmed ids and fetch the citation json...\n",
    "# takes a good bit of time with a large list.\n",
    "# Manubot, which uses NCBI, I presume is taking time\n",
    "ids = [f\"pubmed:{id}\" for id in id_dict.keys()]\n",
    "\n",
    "# print(\"IDs: \", ids)\n",
    "\n",
    "citations = Citations(ids, prune_csl_items=False)\n",
    "\n",
    "print(\"Built citations, running get_csl_items...\")\n",
    "cites = citations.get_csl_items()\n",
    "# cites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes, in what I can only figure are sunspots or something,\n",
    "# an author dictionary in 'authors' will be empty... and this\n",
    "# causes big problems down the line. So I remove the empties.\n",
    "for cite in cites:\n",
    "    while {} in cite[\"author\"]:\n",
    "        cite[\"author\"].remove({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d664dd-d05d-4783-aa92-e1ced8b803a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d882fd-c994-47a0-81c1-1531ed8dd9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11fd8bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I'm going to want to sort these later.\n",
    "for rec in cites:\n",
    "    key = rec[\"PMID\"]\n",
    "\n",
    "    id_dict[key][\"csljson\"] = rec\n",
    "    id_dict[key][\"title\"] = rec.get(\"title\", \"NO_TITLE\").strip()\n",
    "\n",
    "    # all this for the date!\n",
    "    if rec.get(\"issued\"):\n",
    "        issued_date_parts = rec[\"issued\"][\"date-parts\"][0]\n",
    "        date_str = str(issued_date_parts[0])\n",
    "        try:\n",
    "            date_str += f\"/{issued_date_parts[1]}\"\n",
    "            try:\n",
    "                date_str += f\"/{issued_date_parts[2]}\"\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        id_dict[key][\"issued_date\"] = date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0ad0f-fa8f-442d-8a1a-b70fc6aafaf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56b180",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort the dictionary\n",
    "df = pd.DataFrame.from_dict(id_dict, orient=\"index\")\n",
    "\n",
    "df.sort_values(by=\"title\", inplace=True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the counts by author\n",
    "author_counts_df = (\n",
    "    df.explode(\"authors\")\n",
    "    .groupby(\"authors\")[\"title\"]\n",
    "    .count()\n",
    "    .to_frame()\n",
    "    .rename(columns={\"title\": \"title count\"})\n",
    ")\n",
    "\n",
    "# merge the counts into our main author df\n",
    "author_info_df = authors_df.merge(author_counts_df, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5159fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the citation style\n",
    "# (we presume here that the folder with the notebook is the current working directory)\n",
    "bib_style = CitationStylesStyle(\"manubot-style-title-case.csl\")\n",
    "# bib_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba892a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bibliography(cites: List):\n",
    "    \"\"\"\n",
    "    Create the citeproc-py bibliography, passing it the:\n",
    "      * CitationStylesStyle,\n",
    "      * BibliographySource (CiteProcJSON in this case), and\n",
    "      * a formatter (plain, html, or you can write a custom formatter)\n",
    "\n",
    "    Created as function to hand in cites one at a time\n",
    "    \"\"\"\n",
    "    # process the citations into a bib source\n",
    "    bib_source = CiteProcJSON(cites)\n",
    "\n",
    "    bibliography = CitationStylesBibliography(bib_style, bib_source, formatter.html)\n",
    "\n",
    "    # register the citations in the bibliography\n",
    "    for key, entry in bib_source.items():\n",
    "        citation = Citation([CitationItem(key)])\n",
    "        bibliography.register(citation)\n",
    "\n",
    "    return bibliography.bibliography()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through the cites one at a time\n",
    "cite_markdown = []\n",
    "for cite in cites:\n",
    "    new_dict = {\"PMID\": cite[\"PMID\"]}\n",
    "\n",
    "    # I'm only handing them in one at a time\n",
    "    result = create_bibliography([cite])\n",
    "    new_dict[\"markdown\"] = str(result[0])\n",
    "\n",
    "    cite_markdown.append(new_dict)\n",
    "\n",
    "# create a df for merging\n",
    "cite_markdown_df = pd.DataFrame(cite_markdown).set_index(\"PMID\")\n",
    "# cite_markdown_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae22fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manubot gives out HTML, and <i> is interpreted correctly,\n",
    "# but maybe because <b> isn't <strong> or something,\n",
    "# the HTML doesn't quite all work. Thus replacing...\n",
    "# somewhat roughly\n",
    "\n",
    "\n",
    "def markdown_me(row):\n",
    "    temp_line = row[\"markdown\"]\n",
    "    temp_line = temp_line.replace(\"<b>\", \" **\").replace(\"</b>\", \"** \")\n",
    "    temp_line = temp_line.replace(\"<i>\", \"_\").replace(\"</i>\", \"_\")\n",
    "    row[\"markdown\"] = temp_line\n",
    "    return row\n",
    "\n",
    "\n",
    "cite_markdown_df = cite_markdown_df.apply(markdown_me, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a45e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally a reporting DF\n",
    "report_df = df.merge(cite_markdown_df, left_index=True, right_index=True)\n",
    "# report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5262b5-9d34-4697-9f59-8a44403562f5",
   "metadata": {},
   "source": [
    "## Write out Summary Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e961c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write out the report dataframe to a spreadsheet\n",
    "out_sheet = os.path.join(BUILD_FOLDER, BUILD_SHEET_FILENAME)\n",
    "with open(out_sheet, \"wb\") as f:\n",
    "    publication_df = df[[\"authors\", \"title\", \"issued_date\"]]\n",
    "    publication_df.to_excel(f)\n",
    "    log.info(f\"Wrote out {out_sheet}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bded28f",
   "metadata": {},
   "source": [
    "## Build up the markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75c5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log.info(f\"Writing file {BUILD_MARKDOWN_FILENAME} to {BUILD_FOLDER}\")\n",
    "with open(\n",
    "    os.path.join(BUILD_FOLDER, BUILD_MARKDOWN_FILENAME), \"w\", encoding=\"utf-8\"\n",
    ") as f:\n",
    "    if department_name is not None and str(department_name).strip() != \"\":\n",
    "        f.write(f\"# {department_name}\\n\\n\")\n",
    "\n",
    "    f.write(f\"## Published Items Bibliography\\n\\n\")\n",
    "    f.write(f\"For the period {month_starting_date} to {month_ending_date}\\n\\n\")\n",
    "\n",
    "    # In the custom CSL, I don't include the citation number.\n",
    "    # This is just a numbered list now.\n",
    "    for index, row in report_df.iterrows():\n",
    "        f.write(f\"{row['markdown']}\\n\\n\")\n",
    "        for author in row[\"authors\"]:\n",
    "            f.write(f\" &mdash; <cite>{author}</cite>\\n\\n\")\n",
    "        f.write(\"***\\n\")\n",
    "\n",
    "    f.write(f\"## Authors and Search Terms\\n\\n\")\n",
    "    f.write(f\"Please contact the DBMI A&O staff for changes to name, ORCID, or search terms.\\n\\n\")\n",
    "\n",
    "    f.write(f\"|Author|NCBI Search Term|ORCiD|Title Count\\n\")\n",
    "    f.write(f\"|---|---|---|---\\n\")\n",
    "    for index, row in author_info_df.iterrows():\n",
    "        f.write(\n",
    "            f\"|{index}|{row['NCBI search term']}|{row['ORCID number']}|{row['title count']}\\n\"\n",
    "        )\n",
    "\n",
    "    if skipped_authors:\n",
    "        f.write(f\"## Skipped Searches\\n\\n\")\n",
    "        f.write(f\"The following authors have been skipped due to a missing NCBI search term and missing ORCID.\\n\\n\")\n",
    "\n",
    "        for author in skipped_authors:\n",
    "            f.write(\n",
    "                f\"- {author}\\n\"\n",
    "            )\n",
    "        \n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Generated {prepared_date}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62273b07",
   "metadata": {},
   "source": [
    "## Convert markdown to pdf and docx\n",
    "\n",
    "**experimental!**\n",
    "\n",
    "A very trick little docker container for wrapping pandoc. Very helpful. https://github.com/davidlougheed/reformed\n",
    "\n",
    "To run a local version:\n",
    "\n",
    "    docker run -d --name reformed -p 8088:8000 ghcr.io/davidlougheed/reformed:sha-1b8f46b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405dcd7-a634-4490-9e1b-c1e3b69d9307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert(input_path, input_fmt, output_path, output_fmt):\n",
    "    url = f\"http://localhost:8088/api/v1/from/{input_fmt}/to/{output_fmt}\"\n",
    "    \n",
    "    try:\n",
    "        with open(input_path, \"rb\") as f:\n",
    "            r = requests.post(url, files={\"document\": f.read()})\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            raise Exception(f\"Non-200 response, code {r.status_code}\")\n",
    "\n",
    "        print(f\"Read in {input_path}, outputted to {output_path}\")\n",
    "    except Exception as ex:\n",
    "        print(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c81a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"http://localhost:8088/api/v1/from/markdown/to/pdf\"\n",
    "\n",
    "input_path = os.path.join(BUILD_FOLDER, BUILD_MARKDOWN_FILENAME)\n",
    "output_path = os.path.join(BUILD_FOLDER, BUILD_PDF_FILENAME)\n",
    "\n",
    "convert(\n",
    "    input_path = os.path.join(BUILD_FOLDER, BUILD_MARKDOWN_FILENAME), input_fmt=\"markdown\",\n",
    "    output_path = os.path.join(BUILD_FOLDER, BUILD_PDF_FILENAME), output_fmt=\"pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9782e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"http://localhost:8088/api/v1/from/markdown/to/docx\"\n",
    "\n",
    "convert(\n",
    "    input_path = os.path.join(BUILD_FOLDER, BUILD_MARKDOWN_FILENAME), input_fmt=\"markdown\",\n",
    "    output_path = os.path.join(BUILD_FOLDER, BUILD_DOCX_FILENAME), output_fmt=\"docx\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
