{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2747125",
   "metadata": {},
   "source": [
    "# Published Items for the Center for Health AI - Monthly\n",
    "\n",
    "This takes a list of authors and searches for any items published for the provided month, grabs the proper citation from manubot-cite, and creates a markdown and MS Word document.\n",
    "\n",
    "The smartsheet with the author search terms can be found here: https://app.smartsheet.com/sheets/rCfg3F64V9c4wH6Q9vcwQwqxF8XqhWJchpQfgRR1?view=grid\n",
    "\n",
    "- 2021/12/20 First demo (ST)\n",
    "- 2022/01/18 Fetch pubmed instead of PMC ids (ST)\n",
    "- 2022/01/19 Added caching to help dev go faster (ST)\n",
    "- 2022/06/24 Changes for monthly counts (DB)\n",
    "- 2022/06/12 Pull user list from smartsheet (ST)\n",
    "- 2022/08/09 Include ORCiD in search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33d948-2ec7-499a-b19f-ce03d177f21f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T22:47:42.868968Z",
     "iopub.status.busy": "2023-02-03T22:47:42.868571Z",
     "iopub.status.idle": "2023-02-03T22:47:48.942603Z",
     "shell.execute_reply": "2023-02-03T22:47:48.941595Z",
     "shell.execute_reply.started": "2023-02-03T22:47:42.868934Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import copy\n",
    "import subprocess\n",
    "from dateutil import parser\n",
    "from datetime import date, datetime, timedelta\n",
    "from typing import Dict, List, Union\n",
    "import numpy as np\n",
    "import manubot\n",
    "import pandas as pd\n",
    "import requests\n",
    "import smartsheet\n",
    "import scrapbook as sb\n",
    "import dotenv\n",
    "\n",
    "from prefect import task, flow\n",
    "from prefect.client import get_client\n",
    "\n",
    "from manubot.cite.citations import Citations\n",
    "from manubot.cite.citekey import citekey_to_csl_item\n",
    "from citeproc.source.json import CiteProcJSON\n",
    "from citeproc import CitationStylesStyle, CitationStylesBibliography\n",
    "from citeproc import Citation, CitationItem\n",
    "from citeproc import formatter\n",
    "\n",
    "from ratelimit import RateLimitException, limits, sleep_and_retry\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e253856-8f0f-43e9-aa09-5a008ac819d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T22:47:48.948060Z",
     "iopub.status.busy": "2023-02-03T22:47:48.947017Z",
     "iopub.status.idle": "2023-02-03T22:47:48.957855Z",
     "shell.execute_reply": "2023-02-03T22:47:48.955846Z",
     "shell.execute_reply.started": "2023-02-03T22:47:48.948007Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set variables from the environment\n",
    "BUILD_FOLDER_PREFIX = os.environ.get(\"BUILD_FOLDER_PREFIX\", \"/app/_build\")\n",
    "\n",
    "# (Optional) NCBI API key\n",
    "NCBI_API_KEY = os.environ.get('NCBI_API_KEY')\n",
    "# (Optional) NCBI API email\n",
    "NCBI_API_EMAIL = os.environ.get('NCBI_API_EMAIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0aa77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T22:47:48.960352Z",
     "iopub.status.busy": "2023-02-03T22:47:48.959638Z",
     "iopub.status.idle": "2023-02-03T22:47:48.967558Z",
     "shell.execute_reply": "2023-02-03T22:47:48.966042Z",
     "shell.execute_reply.started": "2023-02-03T22:47:48.960301Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Papermill Parameters Cell\n",
    "# These can be used as arguments via papermill\n",
    "\n",
    "# Set any dates (as string in the format yyyy/mm/dd) for searching a month's cites\n",
    "# Leave these empty to generate for the current month.\n",
    "start_date: str = \"2023/01/01\"\n",
    "end_date: str = \"2023/01/31\"\n",
    "\n",
    "# this is the ID from jerome's \"DBMI Contact List\" spreadsheet\n",
    "# it appears to contain the correct info, so we're going with this\n",
    "authors_sheet_id:int = os.environ.get('AUTHORS_SHEET_ID', -1)\n",
    "\n",
    "# alternatively, the user may supply a path to a file\n",
    "authors_sheet_path:str = os.environ.get('AUTHORS_SHEET_PATH')\n",
    "\n",
    "# the name of the department by which to filter authors, i.e. the value on which to match against the \"Primary Department\" column\n",
    "# if null or blank, disables filtering by department\n",
    "department:str = \"DBMI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f7e0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T22:47:48.972419Z",
     "iopub.status.busy": "2023-02-03T22:47:48.971578Z",
     "iopub.status.idle": "2023-02-03T22:47:48.981507Z",
     "shell.execute_reply": "2023-02-03T22:47:48.979991Z",
     "shell.execute_reply.started": "2023-02-03T22:47:48.972369Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the environment vars for secrets\n",
    "\n",
    "try:\n",
    "    env_file = \"/app/.env\"\n",
    "    log.info(\"Loading the .env file from %s\", env_file)\n",
    "    dotenv.load_dotenv(dotenv.find_dotenv(env_file))\n",
    "except OSError:\n",
    "    print(\".env file not found, continuing...\")\n",
    "\n",
    "assert os.environ.get(\"SMARTSHEET_KEY\"), f\"SMARTSHEET_KEY not found in the environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ea81b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T22:47:48.984699Z",
     "iopub.status.busy": "2023-02-03T22:47:48.983846Z",
     "iopub.status.idle": "2023-02-03T22:47:48.993997Z",
     "shell.execute_reply": "2023-02-03T22:47:48.992228Z",
     "shell.execute_reply.started": "2023-02-03T22:47:48.984651Z"
    }
   },
   "outputs": [],
   "source": [
    "def month_end_date(a_date: str) -> (str, str):\n",
    "    \"\"\"\n",
    "    Calculate the month start and end date, given _any_ date.\n",
    "\n",
    "    Returns month_start_date, month_end_date.\n",
    "    \"\"\"\n",
    "    date_format_string = \"%Y/%m/%d\"\n",
    "\n",
    "    this_date = datetime.strptime(a_date, date_format_string)\n",
    "    month = this_date.month\n",
    "    year = this_date.year\n",
    "\n",
    "    start_date = f\"{year}/{month}/1\"\n",
    "\n",
    "    month += 1\n",
    "    if month == 13:\n",
    "        month = 1\n",
    "        year += 1\n",
    "\n",
    "    work_date = datetime.strptime(f\"{year}/{month}/1\", date_format_string)\n",
    "    end_date = (work_date - timedelta(days=1)).strftime(date_format_string)\n",
    "\n",
    "    return start_date, end_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2220454-3122-4fa8-81f8-28a9df3675b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T22:47:48.997031Z",
     "iopub.status.busy": "2023-02-03T22:47:48.995931Z",
     "iopub.status.idle": "2023-02-03T22:47:49.007294Z",
     "shell.execute_reply": "2023-02-03T22:47:49.005881Z",
     "shell.execute_reply.started": "2023-02-03T22:47:48.996984Z"
    }
   },
   "outputs": [],
   "source": [
    "prepared_date = datetime.today().strftime(\"%Y/%m/%d\")\n",
    "\n",
    "if end_date:\n",
    "    # if the parameter date has been set, use it...\n",
    "    month_starting_date, month_ending_date = month_end_date(end_date)\n",
    "else:\n",
    "    # ... otherwise use today.\n",
    "    month_starting_date, month_ending_date = month_end_date(prepared_date)\n",
    "\n",
    "BUILD_MARKDOWN_FILEROOT = f\"cites_monthly-{month_ending_date.replace('/','-')}\"\n",
    "BUILD_MARKDOWN_FILENAME = f\"{BUILD_MARKDOWN_FILEROOT}.md\"\n",
    "BUILD_SHEET_FILENAME = f\"{BUILD_MARKDOWN_FILEROOT}.xlsx\"\n",
    "BUILD_PDF_FILENAME = f\"{BUILD_MARKDOWN_FILEROOT}.pdf\"\n",
    "BUILD_DOCX_FILENAME = f\"{BUILD_MARKDOWN_FILEROOT}.docx\"\n",
    "\n",
    "print(month_starting_date, month_ending_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b98f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T22:47:49.010297Z",
     "iopub.status.busy": "2023-02-03T22:47:49.009463Z",
     "iopub.status.idle": "2023-02-03T22:47:49.023151Z",
     "shell.execute_reply": "2023-02-03T22:47:49.021972Z",
     "shell.execute_reply.started": "2023-02-03T22:47:49.010255Z"
    }
   },
   "outputs": [],
   "source": [
    "# override the month start date from parameters if any\n",
    "if start_date:\n",
    "    month_starting_date = start_date\n",
    "\n",
    "month_starting_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc56cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T22:47:49.025981Z",
     "iopub.status.busy": "2023-02-03T22:47:49.025134Z",
     "iopub.status.idle": "2023-02-03T22:47:49.034585Z",
     "shell.execute_reply": "2023-02-03T22:47:49.033017Z",
     "shell.execute_reply.started": "2023-02-03T22:47:49.025925Z"
    }
   },
   "outputs": [],
   "source": [
    "# set rate limit based on whether there's an API_KEY\n",
    "# based on NCBI requirements\n",
    "if NCBI_API_KEY:\n",
    "    NCBI_RATE_LIMIT = 10\n",
    "else:\n",
    "    NCBI_RATE_LIMIT = 3\n",
    "\n",
    "NCBI_RATE_LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977e046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-03T22:47:49.037138Z",
     "iopub.status.busy": "2023-02-03T22:47:49.036439Z",
     "iopub.status.idle": "2023-02-03T22:47:49.044018Z",
     "shell.execute_reply": "2023-02-03T22:47:49.042658Z",
     "shell.execute_reply.started": "2023-02-03T22:47:49.037093Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure the output folder exists, and group the results of this run into a folder created from the start and end date\n",
    "BUILD_FOLDER = os.path.join(BUILD_FOLDER_PREFIX, f\"{month_starting_date}_to_{month_ending_date}\".replace(\"/\", \"-\"))\n",
    "\n",
    "# will write out to a folder\n",
    "if not os.path.exists(BUILD_FOLDER):\n",
    "    os.makedirs(BUILD_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbce8c",
   "metadata": {},
   "source": [
    "## Fetch authors list\n",
    "\n",
    "Uses whichever one of `authors_sheet_id` or `authors_sheet_path` is specified to fetch the list of authors. If it's the `_id` version, the sheet is fetched from Smartsheet by its ID, whereas if it's `_path` it's loaded from a local Excel/CSV file. If both are specified, an error is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d53b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T15:39:39.608158Z",
     "iopub.status.busy": "2023-02-06T15:39:39.607696Z",
     "iopub.status.idle": "2023-02-06T15:39:40.940469Z",
     "shell.execute_reply": "2023-02-06T15:39:40.939405Z",
     "shell.execute_reply.started": "2023-02-06T15:39:39.608121Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "author_sheet_valid = authors_sheet_path is not None and authors_sheet_path.strip() != \"\"\n",
    "\n",
    "if author_sheet_valid:\n",
    "    print(f\"Loading authors from local spreadsheet file: {authors_sheet_path}\")\n",
    "    \n",
    "    from pathlib import Path\n",
    "    # load up the local file instead\n",
    "    pth = Path(authors_sheet_path)\n",
    "    authors_df = pd.read_excel(pth)\n",
    "    \n",
    "elif authors_sheet_id is not None and str(authors_sheet_id).strip() != '' and int(authors_sheet_id) != -1:\n",
    "    print(f\"Loading authors from Smartsheet by ID: {authors_sheet_id}\")\n",
    "    \n",
    "    # connect smartsheet client\n",
    "    ss_client = smartsheet.Smartsheet(os.environ.get(\"SMARTSHEET_KEY\"))\n",
    "    ss_client.errors_as_exceptions(True)\n",
    "\n",
    "    # authors_sheet = ss_client.Reports.get_report(authors_sheet_id)\n",
    "    # the above fetched a report, but i have no idea what that is...\n",
    "    # we'll fetch the sheet instead using the \"alt\" ID\n",
    "    authors_sheet = ss_client.Sheets.get_sheet(authors_sheet_id)\n",
    "\n",
    "    # break down the cell IDs into a quick lookup box\n",
    "    cell_ids = [\"Row ID\"]\n",
    "    for column in authors_sheet.columns:\n",
    "        my_column = column.to_dict()\n",
    "        cell_ids.append(my_column[\"title\"])\n",
    "\n",
    "    # cell_ids\n",
    "\n",
    "    # break down the cells into a list of lists for a later dataframe\n",
    "    rows_list = []\n",
    "    for row in authors_sheet.rows:\n",
    "        row_list = [row.id]\n",
    "        for cell in row.cells:\n",
    "            if cell.display_value:\n",
    "                row_list.append(cell.display_value)\n",
    "            else:\n",
    "                # just in case there's a None in here, use NaN instead\n",
    "                if cell.value:\n",
    "                    row_list.append(cell.value)\n",
    "                else:\n",
    "                    row_list.append(np.NaN)\n",
    "\n",
    "        rows_list.append(row_list)\n",
    "    \n",
    "    # put it together as a dataframe\n",
    "    authors_df = pd.DataFrame(rows_list, columns=cell_ids)\n",
    "\n",
    "else:\n",
    "    raise Exception(\"One of authors_sheet_path or authors_sheet_id must be specified, but neither were provided.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd648053",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only want primary\n",
    "if department and department.strip() != \"\":\n",
    "    authors_df = authors_df.loc[authors_df[\"Primary Department\"] == department]\n",
    "\n",
    "authors_df.set_index(\"Official Name\", inplace=True)\n",
    "authors_df[\"NCBI search term\"].fillna(\"\", inplace=True)\n",
    "authors_df[\"ORCID number\"].fillna(\"\", inplace=True)\n",
    "# authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ac9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_term(row):\n",
    "    \"\"\"\n",
    "    Function to build up the search term. Used by a dataframe apply()\n",
    "    \n",
    "    https://pubmed.ncbi.nlm.nih.gov/help/\n",
    "    \"\"\"\n",
    "    \n",
    "    search_terms = []\n",
    "    \n",
    "    if row['ORCID number']:\n",
    "        orcid_term = f\"(orcid {row['ORCID number']} [auid])\"\n",
    "        #orcid_term = f\"({row['ORCID number']}[Author - Identifier])\"\n",
    "        search_terms.append(orcid_term)\n",
    "        \n",
    "    if row[\"NCBI search term\"]:\n",
    "        search_terms.append(row[\"NCBI search term\"])\n",
    "\n",
    "    if len(search_terms) > 0:\n",
    "        # group the search terms with an OR, then and that group with CU\n",
    "        return f'(({\" OR \".join(search_terms)}) AND (\"University of Colorado\"))'\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d22ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the logic for the search terms\n",
    "authors_df['full NCBI search term'] = authors_df.apply(build_search_term, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531499e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cache requests to NCBI so these can be accelerated on subsequent runs\n",
    "import requests_cache\n",
    "\n",
    "session = requests_cache.CachedSession('ncbi_authors_cache')\n",
    "\n",
    "@sleep_and_retry\n",
    "# @limits(calls=NCBI_RATE_LIMIT, period=60)\n",
    "def search_ncbi(\n",
    "    term: str,\n",
    "    mindate: str,\n",
    "    maxdate: str,\n",
    "    api_key: str = None,\n",
    "    email: str = NCBI_API_EMAIL,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Look up IDs given a search term,\n",
    "    a beginning year, and an optional API key.\n",
    "\n",
    "    NCBI asks that we use an API key,\n",
    "    which increases API calls to 10/minute, instead of 3/minute.\n",
    "\n",
    "    Returns status code and a list of IDs\n",
    "    \"\"\"\n",
    "\n",
    "    # log.info(f\"Looking up NCBI records for {term}, between {mindate} and {maxdate}.\")\n",
    "    ids = []\n",
    "\n",
    "    params = {\n",
    "        \"term\": term,\n",
    "        \"format\": \"pmid\",\n",
    "        \"tool\": \"CUAnschutz-Center_for_Health_AI-DEV\",\n",
    "        \"email\": email,\n",
    "        \"format\": \"json\",\n",
    "        \"retmax\": 100,\n",
    "        \"retstart\": 0,\n",
    "        # note: date format is in yyyy/mm/dd\n",
    "        \"mindate\": mindate,\n",
    "        \"maxdate\": maxdate,\n",
    "    }\n",
    "\n",
    "    if api_key:\n",
    "        params[\"api_key\"] = api_key\n",
    "\n",
    "    # page through the results until there are no more ids\n",
    "    while True:\n",
    "        r = session.get(\n",
    "            \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\", params=params\n",
    "        )\n",
    "        if r.status_code == 200:\n",
    "            result = r.json()[\"esearchresult\"]\n",
    "        else:\n",
    "            log.error(f\"NCBI returned a status code of {r.status_code}.\")\n",
    "            log.error(\"URL: \", r.url)\n",
    "            log.error(\"Details: \", r.json())\n",
    "            break\n",
    "\n",
    "        if len(result[\"idlist\"]) == 0:\n",
    "            # no more IDs\n",
    "            break\n",
    "        else:\n",
    "            # append the IDs to the results...\n",
    "            ids = ids + result[\"idlist\"]\n",
    "            # and move the start chunk up by the size of retmax\n",
    "            params[\"retstart\"] += params[\"retmax\"]\n",
    "\n",
    "    return r.status_code, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc3a02",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "\n",
    "# I would like to do this in parallel, but the deal with NCBI is we agree not to do that\n",
    "id_dict = {}\n",
    "\n",
    "log.info(\n",
    "    f\"Looking up pubmed IDs from NCBI between {month_starting_date} and {month_ending_date}\"\n",
    ")\n",
    "\n",
    "skipped_authors = set()\n",
    "\n",
    "with logging_redirect_tqdm():\n",
    "    for author, row in tqdm(authors_df.iterrows(), total=authors_df.shape[0]):\n",
    "        if row['full NCBI search term']:\n",
    "            search_term = row['full NCBI search term']\n",
    "        else:\n",
    "            log.warning(f\"Cannot find a search term for `{author}`\")\n",
    "            skipped_authors.add(author)\n",
    "            continue\n",
    "\n",
    "        # log.info(f\"Looking up `{author}` using {search_term}\")\n",
    "        status_code, ids = search_ncbi(\n",
    "            term=search_term,\n",
    "            mindate=month_starting_date,\n",
    "            maxdate=month_ending_date,\n",
    "            api_key=NCBI_API_KEY,\n",
    "        )\n",
    "        # log.debug(\"pubmed ids fetched from NCBI: %s\", ids)\n",
    "\n",
    "        for id in ids:\n",
    "            if not id_dict.get(id):\n",
    "                # create an empty nested dict\n",
    "                id_dict[id] = {\"authors\": []}\n",
    "            id_dict[id][\"authors\"].append(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd20020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a list of pubmed ids and fetch the citation json...\n",
    "# takes a good bit of time with a large list.\n",
    "# Manubot, which uses NCBI, I presume is taking time\n",
    "ids = [f\"pubmed:{id}\" for id in id_dict.keys()]\n",
    "\n",
    "# print(\"IDs: \", ids)\n",
    "\n",
    "citations = Citations(ids)\n",
    "\n",
    "print(\"Built citations, running get_csl_items...\")\n",
    "cites = citations.get_csl_items()\n",
    "# cites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes, in what I can only figure are sunspots or something,\n",
    "# an author dictionary in 'authors' will be empty... and this\n",
    "# causes big problems down the line. So I remove the empties.\n",
    "for cite in cites:\n",
    "    while {} in cite[\"author\"]:\n",
    "        cite[\"author\"].remove({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11fd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to want to sort these later.\n",
    "for rec in cites:\n",
    "    key = rec[\"PMID\"]\n",
    "\n",
    "    id_dict[key][\"csljson\"] = rec\n",
    "    id_dict[key][\"title\"] = rec[\"title\"].strip()\n",
    "\n",
    "    # all this for the date!\n",
    "    if rec.get(\"issued\"):\n",
    "        issued_date_parts = rec[\"issued\"][\"date-parts\"][0]\n",
    "        date_str = str(issued_date_parts[0])\n",
    "        try:\n",
    "            date_str += f\"/{issued_date_parts[1]}\"\n",
    "            try:\n",
    "                date_str += f\"/{issued_date_parts[2]}\"\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        id_dict[key][\"issued_date\"] = date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56b180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort the dictionary\n",
    "df = pd.DataFrame.from_dict(id_dict, orient=\"index\")\n",
    "df.sort_values(by=\"title\", inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the counts by author\n",
    "author_counts_df = (\n",
    "    df.explode(\"authors\")\n",
    "    .groupby(\"authors\")[\"title\"]\n",
    "    .count()\n",
    "    .to_frame()\n",
    "    .rename(columns={\"title\": \"title count\"})\n",
    ")\n",
    "\n",
    "# merge the counts into our main author df\n",
    "author_info_df = authors_df.merge(author_counts_df, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5159fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the citation style\n",
    "# (we presume here that the folder with the notebook is the current working directory)\n",
    "bib_style = CitationStylesStyle(\"manubot-style-title-case.csl\")\n",
    "# bib_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba892a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bibliography(cites: List):\n",
    "    \"\"\"\n",
    "    Create the citeproc-py bibliography, passing it the:\n",
    "      * CitationStylesStyle,\n",
    "      * BibliographySource (CiteProcJSON in this case), and\n",
    "      * a formatter (plain, html, or you can write a custom formatter)\n",
    "\n",
    "    Created as function to hand in cites one at a time\n",
    "    \"\"\"\n",
    "    # process the citations into a bib source\n",
    "    bib_source = CiteProcJSON(cites)\n",
    "\n",
    "    bibliography = CitationStylesBibliography(bib_style, bib_source, formatter.html)\n",
    "\n",
    "    # register the citations in the bibliography\n",
    "    for key, entry in bib_source.items():\n",
    "        citation = Citation([CitationItem(key)])\n",
    "        bibliography.register(citation)\n",
    "\n",
    "    return bibliography.bibliography()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through the cites one at a time\n",
    "cite_markdown = []\n",
    "for cite in cites:\n",
    "    new_dict = {\"PMID\": cite[\"PMID\"]}\n",
    "\n",
    "    # I'm only handing them in one at a time\n",
    "    result = create_bibliography([cite])\n",
    "    new_dict[\"markdown\"] = str(result[0])\n",
    "\n",
    "    cite_markdown.append(new_dict)\n",
    "\n",
    "# create a df for merging\n",
    "cite_markdown_df = pd.DataFrame(cite_markdown).set_index(\"PMID\")\n",
    "# cite_markdown_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae22fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manubot gives out HTML, and <i> is interpreted correctly,\n",
    "# but maybe because <b> isn't <strong> or something,\n",
    "# the HTML doesn't quite all work. Thus replacing...\n",
    "# somewhat roughly\n",
    "\n",
    "\n",
    "def markdown_me(row):\n",
    "    temp_line = row[\"markdown\"]\n",
    "    temp_line = temp_line.replace(\"<b>\", \" **\").replace(\"</b>\", \"** \")\n",
    "    temp_line = temp_line.replace(\"<i>\", \"_\").replace(\"</i>\", \"_\")\n",
    "    row[\"markdown\"] = temp_line\n",
    "    return row\n",
    "\n",
    "\n",
    "cite_markdown_df = cite_markdown_df.apply(markdown_me, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a45e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally a reporting DF\n",
    "report_df = df.merge(cite_markdown_df, left_index=True, right_index=True)\n",
    "# report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5262b5-9d34-4697-9f59-8a44403562f5",
   "metadata": {},
   "source": [
    "## Write out Summary Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e961c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write out the report dataframe to a spreadsheet\n",
    "out_sheet = os.path.join(BUILD_FOLDER, BUILD_SHEET_FILENAME)\n",
    "with open(out_sheet, \"wb\") as f:\n",
    "    publication_df = df[[\"authors\", \"title\", \"issued_date\"]]\n",
    "    publication_df.to_excel(f)\n",
    "    log.info(f\"Wrote out {out_sheet}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bded28f",
   "metadata": {},
   "source": [
    "## Build up the markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75c5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log.info(f\"Writing file {BUILD_MARKDOWN_FILENAME} to {BUILD_FOLDER}\")\n",
    "with open(\n",
    "    os.path.join(BUILD_FOLDER, BUILD_MARKDOWN_FILENAME), \"w\", encoding=\"utf-8\"\n",
    ") as f:\n",
    "    f.write(f\"# Department of Biomedical Informatics (DBMI)\\n\\n\")\n",
    "\n",
    "    f.write(f\"## Published Items Bibliography\\n\\n\")\n",
    "    f.write(f\"For the period {month_starting_date} to {month_ending_date}\\n\\n\")\n",
    "\n",
    "    # In the custom CSL, I don't include the citation number.\n",
    "    # This is just a numbered list now.\n",
    "    for index, row in report_df.iterrows():\n",
    "        f.write(f\"{row['markdown']}\\n\\n\")\n",
    "        for author in row[\"authors\"]:\n",
    "            f.write(f\" &mdash; <cite>{author}</cite>\\n\\n\")\n",
    "        f.write(\"***\\n\")\n",
    "\n",
    "    f.write(f\"## Authors and Search Terms\\n\\n\")\n",
    "    f.write(f\"Please contact the DBMI A&O staff for changes to name, ORCID, or search terms.\\n\\n\")\n",
    "\n",
    "    f.write(f\"|Author|NCBI Search Term|ORCiD|Title Count\\n\")\n",
    "    f.write(f\"|---|---|---|---\\n\")\n",
    "    for index, row in author_info_df.iterrows():\n",
    "        f.write(\n",
    "            f\"|{index}|{row['NCBI search term']}|{row['ORCID number']}|{row['title count']}\\n\"\n",
    "        )\n",
    "\n",
    "    if skipped_authors:\n",
    "        f.write(f\"## Skipped Searches\\n\\n\")\n",
    "        f.write(f\"The following authors have been skipped due to a missing NCBI search term and missing ORCID.\\n\\n\")\n",
    "\n",
    "        for author in skipped_authors:\n",
    "            f.write(\n",
    "                f\"- {author}\\n\"\n",
    "            )\n",
    "        \n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Generated {prepared_date}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62273b07",
   "metadata": {},
   "source": [
    "## Convert markdown to pdf and docx\n",
    "\n",
    "**experimental!**\n",
    "\n",
    "A very trick little docker container for wrapping pandoc. Very helpful. https://github.com/davidlougheed/reformed\n",
    "\n",
    "To run a local version:\n",
    "\n",
    "    docker run -d --name reformed -p 8088:8000 ghcr.io/davidlougheed/reformed:sha-1b8f46b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405dcd7-a634-4490-9e1b-c1e3b69d9307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert(input_path, input_fmt, output_path, output_fmt):\n",
    "    url = f\"http://localhost:8088/api/v1/from/{input_fmt}/to/{output_fmt}\"\n",
    "    \n",
    "    try:\n",
    "        with open(input_path, \"rb\") as f:\n",
    "            r = requests.post(url, files={\"document\": f.read()})\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            raise Exception(f\"Non-200 response, code {r.status_code}\")\n",
    "\n",
    "        print(f\"Read in {input_path}, outputted to {output_path}\")\n",
    "    except Exception as ex:\n",
    "        print(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c81a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"http://localhost:8088/api/v1/from/markdown/to/pdf\"\n",
    "\n",
    "input_path = os.path.join(BUILD_FOLDER, BUILD_MARKDOWN_FILENAME)\n",
    "output_path = os.path.join(BUILD_FOLDER, BUILD_PDF_FILENAME)\n",
    "\n",
    "convert(\n",
    "    input_path = os.path.join(BUILD_FOLDER, BUILD_MARKDOWN_FILENAME), input_fmt=\"markdown\",\n",
    "    output_path = os.path.join(BUILD_FOLDER, BUILD_PDF_FILENAME), output_fmt=\"pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9782e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"http://localhost:8088/api/v1/from/markdown/to/docx\"\n",
    "\n",
    "convert(\n",
    "    input_path = os.path.join(BUILD_FOLDER, BUILD_MARKDOWN_FILENAME), input_fmt=\"markdown\",\n",
    "    output_path = os.path.join(BUILD_FOLDER, BUILD_DOCX_FILENAME), output_fmt=\"docx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810f855-6eb0-4c10-b809-e72e50d428b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
